---
title: "Post about Apple Health"
author: John Goldin
date: '2019-11-01'
categories:
  - R
slug: working-with-apple-health-export
lastmod: '2019-10-06T08:50:22-04:00'
layout: post
type: post
highlight: no
draft: yes
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This post will work through the mechanics of moving data from the Apple Health app
out of your iPhone and into R where you can analyze it. It will dig into the details
of what is in the export data. It will describe in detail the problem of 
adjusting the time stamps for daylight savings time and travel across time zones.
Next it will offer some
tips on how to prepare and clean up the data a bit. Finally, it will 
explore some of the properties of the types of data available
via the Health app. As an example of how one might use the data,
the heart rate data is used to flesh out the description of a visiting to an
emergency room.

##### First, export the data from the Health app

From the Health app on your iPhone, one can export all of the data you are able to view via the Health app. 
Open the Health app on your iPhone. 
To export, you need to first go to your personal settings by
clicking on your icon near the upper right corner of the Browse screen. 
(See the the first screenshot below.)
Click on the icon and you will see some of your personal settings. 
You will need to scroll to the bottom of this page, where you will
see a clickable line "Export All Health Data", as shown in the second screenshot below. 

<style> 
.row {
  display: flex;
}
.column {
  flex: 100%;
  padding: 5px;
}
</style>
<div class="row">
  <div class="column">
    <figure>
      <figcaption> Browse Health app</figcaption>
      <img src="health_app.PNG" alt="health app screenshot1" width="75%" height="100%" align="center"/>
    </figure>
  </div>
  <div class="column">
    <figure>
      <figcaption>Export All Health Data</figcaption>
      <img src="health_export_dialog.PNG" alt="health export screenshot" width="75%" height="100%" align="center"/>
    </figure>
  </div>
</div>
Once you click OK to go ahead with the export, it may take a significant amount of time.
On my iPhone 8 it takes more than five minutes. Once it is complete, you'll get a 
dialog that asks where to send the exported data. I use AirDrop to send it to the
Mac where I am running RStudio. It ends up in the Downloads folder on that Mac.
If you need to move the data to a Windows computer, you may need to send it
via email or Dropbox.
The exported file is named `export.zip`. If you double-click on that file it 
will expand into a folder called `apple_health_export`. The uncompressed file is huge
in comparison with the size of the zip file. In my case, `export.zip` is about
79 megabytes which becomes an `apple_health_export` folder that is 2.45 gigabytes!
In my R code, I uncompress the file into my Downloads folder, which is excluded
from my Time Machine backups.

##### R code to expand the export file and import it as XML data

The R code below shows how to decompress `export.zip` and follow some
basic steps to import it into R. I'm following in the footsteps of
several people who have published code to accomplish these steps.
See  work by [Ryan Praskievicz](https://gist.github.com/ryanpraski/ba9baee2583cfb1af88ca4ec62311a3d), [Taras Kaduk](https://taraskaduk.com/2019/03/23/apple-health/), [Raul Eulogio](https://www.inertia7.com/projects/149), and [Deepankar Datta](https://github.com/deepankardatta/AppleHealthAnalysis) (who has
created a package called AppleHealthAnalysis). I'm sure there are other examples
using R, and there are quite a number of examples using python (e.g., by [Mark Koester](http://www.markwk.com/data-analysis-for-apple-health.html)).

The R code uncompresses the zip file and replaces the `apple_health_export` folder.
(Because of the size of this folder, I try to avoid having multiple copies and also
avoid having it saved to my disk backup.)
The big file inside that folder is `export.xml`. Following the examples sited above, I
use the XML package to covert the major elements of the XML file into
tidy data frames.

```{r load_libraries, messages = FALSE, warnings = FALSE}
library(tidyverse, quietly = TRUE)
#library(jsonlite, quietly = TRUE)
library(lubridate, quietly = TRUE)
library(XML, quietly = TRUE)
library(knitr)
library(kableExtra) 
library(PerformanceAnalytics) # to get correlation matrix
library(janitor) # so that I an use the tabyl function
library(scales) # to help format some tabular data
```
```{r import_xml, echo = TRUE, cache = TRUE, messages = FALSE}
rc <- unzip("~/Downloads/export.zip", exdir = "~/Downloads", overwrite = TRUE)
if (length(rc) != 0) file.remove("~/Downloads/export.zip")
# once unzipped, delete export.zip. Otherwise, the next time Air Drop sends export.zip
# to your mac it will be renamed as export2.zip and you may accidentally process
# an out-of-date set of data.

  # takes a bit more than 20 seconds on my iMac
health_xml <- xmlParse("~/Downloads/apple_health_export/export.xml")
  # takes about 70 seconds on my iMac
health_df <- XML:::xmlAttrsToDataFrame(health_xml["//Record"], stringsAsFactors = FALSE) %>%
    as_tibble() %>% mutate(value = as.numeric(value))

activity_df <- XML:::xmlAttrsToDataFrame(health_xml["//ActivitySummary"], stringsAsFactors = FALSE) %>% 
  as_tibble()
workout_df <-  XML:::xmlAttrsToDataFrame(health_xml["//Workout"], stringsAsFactors = FALSE) %>% 
  as_tibble
clinical_df <- XML:::xmlAttrsToDataFrame(health_xml["//ClinicalRecord"]) %>% 
  as_tibble()
```

I won't get into details of the XML structure of the health export.
For most purposes, the Record, ActivitySummary, Workout, and Clinical data types
will provide all that you are looking for. My expanded Apple Health Export
folder also includes workout GPX files, electrocardiograms, and clinical
records imported from my physician's medical records system.

I have a bit over two years of Apple Watch data in my iPhone. 
After a full career working
as a data analyst, this is the largest number of data points
I have ever dealt with. Extracting the "Record" data  from `export.xml` produces
3.4 million rows and takes about 70 seconds on my 2019 iMac. 

The counts by "type" describe the breadth and quantity of data:
```{r freq_type}
health_df2 <- health_df %>% 
  mutate(source = case_when(
    str_detect(sourceName, "Phone") ~ "Phone",
    str_detect(sourceName, "Watch") ~ "Watch",
    str_detect(sourceName, "Lose It") ~ "Lose It!",
    TRUE ~ "Other"),
    source = factor(source, levels = c("Watch", "Phone", "Lose It!", "Other")))
health_df2 %>% 
  janitor::tabyl(type, source) %>% 
  janitor::adorn_totals("col") %>%  arrange(desc(Total)) %>% 
  janitor::adorn_totals("row") %>% # do column total after arrange
  kable(format.args = list(decimal.mark = " ", big.mark = ","),
        caption = "Frequency by Type and Data Source", format = "markdown") %>% 
  clipr::write_clip(allow_non_interactive = TRUE) %>% print()

```




Most of the data is collected via the Apple Watch. 
Some basic movement data is collected by the iPhone. 
I have been using the *Lose It!* app on my iPhone for about six months to count calories,
and that produces quite a bit of data. 
The free version of the app which I am using does not display much beyond
basic calorie counts. 
It's interesting to see that the more detailed nutrition breakdowns are passed
into the Health app. I haven't attempted to look at any of the nutrition information.

As far as the "Other" category, I'm using an Omron blood pressure cuff 
that can transfer readings to the Omron app on the iPhone via Bluetooth. Those
readings are then updated in the Apple Health database. 
There are a few odds and ends contributed by apps on my iPhone
such as AllTrails, Breathe, and AutoSleep.

Sometimes the same data may be repeated on multiple sources
so it is important to pay attention to `sourceName`.
Note that step counts, flights climbed, and distance walking/running
come from both the Watch and the iPhone. 
On any particular day you probably want to include only one of the sources.
Otherwise you risk double counting. 
Generally I am focused on the Watch data, but I have almost three years of
data from my iPhone before I started wearing the Apple Watch.

The other major XML categories are ActivitySummary, Workout, and ClinicalRecord. 
For ActivitySummary I have one row per
day which basically summarizes some of the intra-day activity data. 
Workout has one row per workout. If I were
still running I would focus much more on that data frame. 
For each workout it shows type, distance, duration, 
and energy burned Most of my workouts are outdoor walks. 
Quite often I forget to end the workout when I end the walk,
which certainly reduces the usefulness of the data. 
But I would imagine that for a runner or a swimmer or a cyclist, 
the Workout information would be interesting and useful.

ClinicalRecord is a bit tricky. 
I have set things up so that my health organization shares my health records with the
Apple Health app.

```{r count_clin_record_types}
clinical_df %>% count(type) %>% kable(format = "markdown", caption = "Types of Clinical Items")
```

In the clinical data frame there is a column called `resourceFilePath` that contains 
the path to a json dataset in the `Apple Health Export/clinical records` folder. Presumably
this would allow you to retrieve items such as individual lab test results. 
I haven't made any attempt to get into this data. I only know what's available
here because I can view it via the Apple Health app.

### The Problem of Time Zones and Daylight Savings

When I first looked at day by day data for resting heart rate I bumped into
problems cause by the issue of time zones. I have about 745 rows of data of type
`HKQuantityTypeIdentifierRestingHeartRate` which should be one per day. 
I quickly discovered I had several days where there were two values in a single day, 
and that was related to
occasions when I traveled by air to a different time zone.

This leads us to a long digression on the subject of computer time stamps and time zones. 
(There is an [entertaining video](https://www.youtube.com/watch?v=-5wpm-gesOY) that describes
the general problem of time stamps and time zones, but it doesn't relate to the specific
problems that I will get into here. It's fun if you want to nerd out on this topic.)

Each item in the records of the health dataset has a creation, start, and end time stamp. In the export dataset
they appear as a character string that looks like this: "2019-04-10 07:10:34 -0400". 
The "-0400" on the end
is because as I write this local time is Eastern Daylight Savings which is four hours 
earlier than UTC (universal
time code). At first I thought that time code info would take care of everything. 
In fact, it is useless.
As near as I can tell, the internal data has no indication of time zone. [^1]
The UTC offset is attached to the datetime information when the data is exported. 
Ever single time stamp in the exported dataset has the same "-0400" offset,
which merely represent my local offset at the time the export was done. 
If I re-exported that data after the
switch to Eastern Standard Time, all of the offsets will appear as "-0500". 
In fact, the exported data has no information about time zone. 
When I did a workout in San Diego in January, the time stamp that was attached to that workout
was the local time when I did the workout. In the export file now it has a UTC offset of "-0400". 
In reality, local time when I did the workout was offset from UTC by "-0800" (i.e.. 8 hours). 
I can tell that this is an issue of how the Apple Health data stores 
the date and time because I can see the issue via the Activity app on my phone,
not just in the export. 
I go into the Activity app on my iPhone and see that it claims I started a walk in England 
on 9/1/2019 at 05:51:58. I'm not that much of an early riser. 
I know from my travel diary that I actually got started four hours later than that
at 09:51:58 local time. 
If I went back to look at the same workout after the change from daylight savings to standard
time, it would appear as 04:51:58 rather than 05:51:58.

[^1]: The documentation for the Apple Health Kit does offer a way for developers to store [time zone meta data](https://developer.apple.com/documentation/healthkit/hkmetadatakeytimezone?language=objc) via the `HKMetadataKeyTimeZone` object. It appears that [not even Apple uses this feature](https://stackoverflow.com/questions/49250964/hkmetadatakeytimezone-is-always-nil-for-health-data-which-is-created-by-apples). And the Apple documentation only suggests using it for sleep data. It would be impractical to try to attach this meta data to every single observation.

When does this matter? 
With a multi-time-zone shift, it's not hard to end up with datetime stamps that appear in
the wrong day. 
Compounding the problem is that items such as resting heart rate are not always
saved in the data at the same hour of the day. 
A number of items like resting heart rate are recorded once per day.
But because of time zone issues, you can end up with two on one day and none on another. 
Also, there may be situations where you want to look at patterns over the course of a day. 
At one point I wanted to look at whether there were periods when my heart rate was 
unusually high during normal sleeping hours. 
I looked for a heart rate above 120 between the hours of 11PM and 6AM. 
I got hits for when I was hiking in a different time zone because the 
datetime stamp appeared to be during those night time hours when in fact the local time
was shifted five or seven hours because of the different time zone.

This is a tricky problem. I use the `lubridate` package to deal with the datetime stamps. 
R relies on a Unix-based standard for dates and time called 
[POSIX](https://en.wikipedia.org/wiki/POSIX) that is implemented as a class 
called POSIXct. You can see lots of references to POSIXct in the `lubridate` documentation. 
The `as_datetime` function in `lubridate` allows you to add a `tz` parameter that 
specifies the time zone. 
The trick is that the time zone is stored as an **attribute** of the vector 
rather than as part of the data. 
If you have a vector of `datetime` data, 
the time zone attribute applies to the entire vector, not to individual elements
in the vector. 
If you want to store time zones that vary within the vector, you need to store them in a separate
vector, and that's not part of the R standard for handling dates and times. 
You're on your own. The `lubridate` package includes some functions to help convert vectors 
from one time zone to another and to deal somewhat with
daylight savings. 
But it does not automatically help with a vector that contains datetime information from
varying time zones (as well as different daylight savings issues). 
(See [Clayton Yochum](https://blog.methodsconsultants.com/posts/timezone-troubles-in-r/) 
for a more detailed discussion of general time zone messiness in R.)

As I searched the web for tips on how to approach this issue, I discovered that
there's a population of people who are working hard to maintain a streak 
in filling their activity rings in the Apple Activity app.
Some of those individuals get frustrated because they are tripped up
by movement across time zones or even changes to daylight savings.
There are a number of tips out there for activity tracking in the face of 
[issue of crossing time zones](https://9to5mac.com/2018/04/02/how-to-fill-apple-watch-activity-rings-while-traveling-timezones/). 

#### My Treatment of Time Zones and the Apple Health Export

Here I describe a solution to the time zone issue, but it is not very elegant.

First I wrote a function `get_my_time_zone` that identifies in what time zone I was 
located during the two year period for which I need time zone info to interpret watch data. The
function hard codes when I landed in a different time zone and therefore changed
the time zone on my watch. That's the aspect of this solution that is not very elegant. 
The function hard codes my personal travel history. It will only work for me.[^2] If I
travel across a time zone I need to remember to edit the function with my travel details.

[^2]: It might be possible to use the Tripit API to get flight information that could be used in the `get_my_time_zone` function.
 
```{r clean_up_time_zones}
get_my_time_zone <- function(dt) {
  # What I'm going for is the time zone used by my watch. 
  # I'm assuming my watch got the local clock time about the
  # same time as the scheduled arrival for my flight.
  time_zone <- case_when(
    (dt >= as_datetime("2018-01-31 16:00:00")) & # trip to RStudio conference
      (dt <= as_datetime("2018-02-07 13:01:00")) ~ "America/Los_Angeles",
    (dt >= as_datetime("2018-04-18 08:00:00")) & # trip to Amsterdam
      (dt <= as_datetime("2018-04-20 13:50:00")) ~  "Europe/Amsterdam",
    (dt >= as_datetime("2018-04-20 13:50:00")) & # trip to Athens
      (dt <= as_datetime("2018-04-30 15:52:00")) ~  "Europe/Athens",
    (dt >= as_datetime("2019-06-21 03:45:00")) & # trip to SW England
      (dt <= as_datetime("2019-07-05 13:25:00")) ~  "Europe/London",
    (dt >= as_datetime("2019-08-28 06:30:00")) & # trip to Manchester
      (dt <= as_datetime("2019-09-10 12:40:00")) ~  "Europe/London",
    TRUE ~ "America/New_York" # good old Eastern time, home sweet home
  )
  return(time_zone)
}
get_my_time_zone <- compiler::cmpfun(get_my_time_zone)
```

Next I need to use `lubridate` functions to adjust the Apple Health export 
time stamps so that the hour corresponds to the local time I actually experienced.


```{r UTC_to_clock_by_tz}
# I will be applying this function to nearly a million times so it's important
# that it be vectorized and compiled. Vectorized is what really counts.
UTC_to_clock_by_tz <- function(dt, time_zone) {
  # adjust a vector of datetime to a specific time zone and report as though it were utc
  tz(dt) <- .sys.timezone    # make sure vector is set to my current local time zone
  utc <- with_tz(dt, tzone = "UTC")   # what is the datetime in terms of UTC
  # with_tz is the key lubridate function that I am relying on. Handles daylight savings as well.
  local <- with_tz(utc, time_zone) # now adjust utc to the time zone I want
  tz(local) <- "UTC"    # treat everything as if it were UTC, even if it isn't, because the whole vector has to be one arbitrary time zone when I bind rows together
  # Although the vector is marked as UTC, I will treat the hour as being whatever the local
  # time was that I experienced then.
  return(local)
}
```

Next I will apply the `UTC_to_clock_by_tz` function to the character time stamps
in the Apple Health Export. The function needs to be applied to a vector with
the same time zone for all elements in the vector. By doing `group_by(start_time_zone)`
before I use the function inside `mutate`, the function will be applied with a 
different time zone for each group. 
That way the function is vectorized for each group and is reasonably fast. 
I have to group the time zones separately for the start date and the end date. Usually
they would be in the same tine zone, but that's not something I can count on. I
also calculate `span` to be the time between the start_date and the end_date. We
will see below how that can be an important diagnostic tool. For heart rate readings
the start and the end time are the same. For that data item, `span` records the amount
of time since the last reading was recorded, using the `lag` function.

```{r adjust_time_stamps, cache = TRUE}
system.time(
  health_df <- health_df %>% 
    mutate(startDate = as_datetime(str_sub(startDate, 1, 19)),
           endDate = as_datetime(str_sub(endDate, 1, 19)),
           creationDate = as_datetime(str_sub(creationDate, 1, 19)),
           start_time_zone = get_my_time_zone(startDate)) %>% 
    group_by(start_time_zone) %>% 
    # assume end_date is in the same time zone as start_date
    mutate(start_date = UTC_to_clock_by_tz(startDate, first(start_time_zone)),
           end_date = UTC_to_clock_by_tz(endDate, first(start_time_zone))) %>% 
    # mutate(end_time_zone = get_my_time_zone(endDate)) %>% 
    # group_by(end_time_zone) %>% 
    # mutate(end_date = UTC_to_clock_by_tz(endDate, first(end_time_zone))) %>% 
    ungroup() %>% 
    mutate(date = as_date(start_date), hour = hour(start_date)) %>% 
    arrange(type, start_date) %>% 
    mutate(span = case_when(
      (type == "HKQuantityTypeIdentifierHeartRate") & (lag(type) == type) ~ as.numeric(start_date) - as.numeric(lag(start_date)),
      TRUE ~ as.numeric(end_date) - as.numeric(start_date)),
    ) %>% 
    select(-startDate, -endDate) # I don't need the character datetime stamp anymore
)
# Here I'll adjust time for workout_df as well
workout_df <- workout_df %>% 
  mutate(startDate = as_datetime(str_sub(startDate, 1, 19)),
         endDate = as_datetime(str_sub(endDate, 1, 19)),
         creationDate = as_datetime(str_sub(creationDate, 1, 19)),
         start_time_zone = get_my_time_zone(startDate)) %>% 
  group_by(start_time_zone) %>% 
  mutate(start_date = UTC_to_clock_by_tz(startDate, first(start_time_zone)),
         end_date = UTC_to_clock_by_tz(endDate, first(start_time_zone))) %>% 
  # mutate(end_time_zone = get_my_time_zone(endDate)) %>% 
  # group_by(end_time_zone) %>% 
  # mutate(end_date = UTC_to_clock_by_tz(endDate, first(end_time_zone))) %>% 
  ungroup() %>% 
  select(-startDate, -endDate)
# I'm going to focus on health_df and workout_df, but I could adjust times in the other df's as well
```

Save some stuff so that I can skip the slow steps above:

```{r interim_save}
save(health_xml, health_df, activity_df, workout_df, clinical_df, file = "interim_save.RData")

# print(load("interim_save.RData"))
```


### Focusing on Items That Vary Within a Day

There are a set of items where multiple measurements are made during the
course of the day. A prime example is heart rate, which records the pulse at
a particular point in time. There also are a number of items
where a quantity is accumulated over a short span of time: steps taken, 
distance traveled, energy burned, flights climbed, period of exercise. All of these
have to do with movement and, as we'll see, are higly correlated.

Each measurement for the movement items has a start time and an end time. In
R terms the time stamp is a `datetime` class. We have already spent a lot
of effort correcting these datetime stamps for travel across time zones and for daylight savings.
Next, let's examine these measurements in more detail. We 
calculated an item called `span` which is the difference between the start and
end of the measurement period in seconds. This provides some useful diagnostic
information about the nature of the measurements.

**Most of these movement mesurements cover a time span of five seconds or less. They 
are created very frequently. The table below shows the number of measurements broken 
down by the span of time which the measurement covers. For example, the row that shows
steps is nut the total number of steps, it is the number of times a step measurement is
saved (where each measurement probably counts more than one step). There are a lot of 
measurements that cover a period less than a minute. The watch (and phone) are being very
busy saving separate measurements.**

I wanted to look at how frequently measurements are taken. I realized that I needed to consider
whether measurements were taken during a workout. 
A **workout** is a feature of the Apple Watch. You start a 
workout to record a period of physical activity and specify the type of activity. After
you indicate that the workout is finished, Apple provides a summary of the activity (and
saves that summary information in `activity_df`). You can view the summaries of your
workouts via the Activity app on the
During a workout, the watch records measurements much more frquently. 
It doesn't makes sense to examine how frequently measurements are made
without considering whether or not they occur during a workout. 

It's tricky to identify which measurements were
taken during workouts. We have to combine the `health_df` table with the `actiity_df` table. For
each workout there is a start and an end time. I need to join the `health_df` table
with the `workout_df` table. A normal `dplyr` join such as `left_join` won't work because 
we don't have exact matches.
We want to know whether each row in `health_df` is within the range of
the start and end time of any of the workouts.

To relate measurements to particular workouts, I used the 
[fuzzyjoin package](https://github.com/dgrtwo/fuzzyjoin) by Dave Robinson.
It provides a variety of special joins that do not rely on an exact match.
In this case, we will use the `interval_left_join` function which joins tables based
on overlapping intervals. The help for interval_left_join explains that this function requires
the IRanges package available from Bioconductor and points to 
[instructions for installation](https://bioconductor.org/packages/release/bioc/html/IRanges.html).
This was the first time I have used anything from the Bioconductor repository. I'm
impressed by the speed of `interval_left_join`. I thought it would be impractical to run it
on the full dataset, but it took less than 10 seconds to join 434 workouts to 3.3 million
rows in the health_df table.

```{r examine_span, cache = TRUE, echo = FALSE}
earliest_watch_data <- min(health_df$start_date[str_detect(health_df$sourceName, "Watch")], na.rm = TRUE)
# pick out the intra-day movement items plus heart rate
movement <- health_df %>% 
  filter(as_date(start_date) >= ymd("2017-10-03"),
    type %in% c("HKQuantityTypeIdentifierActiveEnergyBurned", "HKQuantityTypeIdentifierBasalEnergyBurned", "HKQuantityTypeIdentifierDistanceWalkingRunning",
                     "HKQuantityTypeIdentifierDistanceCycling", "HKQuantityTypeIdentifierStepCount",
                      "HKQuantityTypeIdentifierFlightsClimbed", "HKQuantityTypeIdentifierAppleExerciseTime",
                     "HKQuantityTypeIdentifierHeartRate"),
         (str_detect(sourceName, "Watch") | str_detect(sourceName, "Phone"))) %>% 
  mutate(type = case_when(
    type == "HKQuantityTypeIdentifierActiveEnergyBurned" ~ "Active_Energy",
    type == "HKQuantityTypeIdentifierBasalEnergyBurned" ~ "Basal_Energy",
    (type == "HKQuantityTypeIdentifierDistanceWalkingRunning") & str_detect(sourceName, "Phone") ~ "Walking_Phone",
    (type == "HKQuantityTypeIdentifierDistanceWalkingRunning") & str_detect(sourceName, "Watch") ~ "Walking_Watch",
    type == "HKQuantityTypeIdentifierDistanceCycling" ~ "Cycling",
    (type == "HKQuantityTypeIdentifierFlightsClimbed") & str_detect(sourceName, "Phone")  ~ "Climb_Phone",
    (type == "HKQuantityTypeIdentifierFlightsClimbed") & str_detect(sourceName, "Watch")  ~ "Climb_Watch",
    (type == "HKQuantityTypeIdentifierStepCount") & str_detect(sourceName, "Phone") ~ "Steps_Phone",
     (type == "HKQuantityTypeIdentifierStepCount") & str_detect(sourceName, "Watch") ~ "Steps_Watch",
    (type == "HKQuantityTypeIdentifierAppleExerciseTime") & str_detect(sourceName, "Phone") ~ "Exercise_Phone",
    (type == "HKQuantityTypeIdentifierAppleExerciseTime") & str_detect(sourceName, "Watch") ~ "Exercise_Watch",
    type == ("HKQuantityTypeIdentifierHeartRate")  & str_detect(sourceName, "Watch") ~ "Heart_Rate"
  ),
  hour = hour(start_date), date_start = (as_date(start_date)),
  span2 = case_when(
    span <= 30 ~ "<=0.5",
    span <= (2 * 60) ~ "0.5-2",
    span <= (10 * 60) ~ "2-10",
    span <= (30*60) ~ "10-30",
    span <= (30*60) ~ "30-60",
    TRUE ~ ">60"
  ),
  # span2 is range of intervals (in minutes rather than in seconds)
  span2 = factor(span2, levels = c("<=0.5", "0.5-2", "2-10", "10-30", "30-60", ">60" ))) %>% 
  # next we will use interval_left_join to get workout info
  # interval_join doesn't work unless the end_date is greater than the start_date, 
  # so add one second to the end_date of the heart rate measurements.
  mutate(start = start_date, end = end_date, 
    end = if_else(type == "Heart_Rate", end + seconds(1), end)) %>%   
  filter(end > start) %>% 
  interval_left_join(
    workout_df %>% select(start = start_date, end = end_date, workoutActivityType, totalEnergyBurned) %>%
      filter(end > start)) 
  # get workout length by day
workout_length <- workout_df %>% filter(str_detect(sourceName, "Watch")) %>% 
  mutate(date_start = as_date(start_date), workout_length = as.numeric(duration), 
         workout_energy = as.numeric(totalEnergyBurned), workout_distance = as.numeric(totalDistance)) %>% 
  group_by(date_start) %>% 
  summarize(workout_length = sum(workout_length, na.rm = TRUE), workout_energy = sum(workout_energy, na.rm = TRUE),
            workout_distance = sum(workout_distance, na.rm = TRUE)) %>% 
  ungroup()
movement <- movement %>% 
  left_join(workout_length, by = "date_start") %>% 
  mutate(group = case_when(
           !is.na(workoutActivityType) ~ "Workout",
           (hour > 23) | (hour < 6) ~ "Sleep",
           TRUE ~ "Day"))

# movement %>% mutate(span_minutes = span / 60, wday = wday(start_date, label = TRUE)) %>% filter((type == "Active_Energy"), span_minutes > (15)) %>% select(sourceVersion, start_date, end_date, span_minutes, wday) %>% View()

# movement %>% 
#  janitor::tabyl(type, span2) %>% 
#   kable(format.args = list(decimal.mark = " ", big.mark = ","),
#         caption = "Size of Interval (in Minutes)", format = "markdown") %>% 
#   clipr::write_clip(allow_non_interactive = TRUE) %>% print()
```



```{r count_measurements}
# let's focus on frequency of movement measurements (and heart rate)
movement2 <- movement %>% 
  filter(type %in% c("Active_Energy", "Heart_Rate", "Basal_Energy", 
                      "Steps_Watch", "Walking_Watch", "Steps_Phone", "Walking_Phone")) %>% 
  group_by(date_start, group) %>% 
  summarise(Active_Energy = sum(type == "Active_Energy"),
            Basal_Energy = sum(type == "Basal_Energy"),
             Heart_Rate = sum(type == "Heart_Rate"),
            Steps = sum(type == "Steps_Watch"),
            Distance = sum(type == "Walking_Watch"),
            Steps_Phone = sum(type == "Steps_Phone"),
            Distance_Phone = sum(type == "Walking_Phone"),
            workout_length = first(workout_length)
           ) 
items_per_minute <- movement2 %>% 
  mutate(
    workout_minutes = ifelse(is.na(workout_length), 0.0, workout_length / 60),
    year = year(date_start),
    period_minutes = case_when(
      group == "Sleep" ~ 6 * 60,
      # used 17.5 hours in formula below to allow for half hour of charging
      group == "Day" ~ (17.5 * 60) - workout_minutes,
      group == "Workout" ~ workout_minutes
    ),
    `Active Energy rate` = if_else(Active_Energy > 0, Active_Energy / period_minutes, NA_real_), 
    `Basal Energy rate` = if_else(Basal_Energy > 0, Basal_Energy / period_minutes, NA_real_), 
    `Pulse readings` = if_else(Heart_Rate > 0, Heart_Rate / period_minutes, NA_real_), 
    `Steps (watch) rate` = if_else(Steps > 0, Steps / period_minutes, NA_real_),
    `Steps (phone) rate` = if_else(Steps_Phone > 0, Steps_Phone / period_minutes, NA_real_),
    `Distance rate` = if_else(Distance > 0, Distance / period_minutes, NA_real_)) 
rate_data <- items_per_minute %>% ungroup() %>% 
  select(group, date_start, `Active Energy rate`, `Basal Energy rate`, `Pulse readings`, `Distance rate`, `Steps (phone) rate`, `Steps (watch) rate`) %>% 
  # group_by(group) %>% 
  pivot_longer(cols = `Active Energy rate`:`Steps (watch) rate`)
ggplot(data = rate_data %>% filter(value < 500), 
       aes(x = date_start, y = value, colour = group)) + geom_point()+
         facet_wrap(~name, scales = "free_y")

ggplot(data = rate_data %>% filter(value < 500), 
       aes(x = value)) + geom_histogram()+
         facet_wrap(name ~ group, scales = "free", ncol = 3)

rate_table <- items_per_minute %>% 
  group_by(year, group) %>% 
  select(year, group, `Active Energy rate`, `Basal Energy rate`, `Pulse readings`, `Distance rate`, `Steps (phone) rate`, `Steps (watch) rate`) %>% 
  summarise_all(median, na.rm = TRUE)
```



```{r explore_outliers}
xx <- rate_data %>% 
  filter(group == "Day", name == "Pulse readings", value > 0.5)
movement %>% filter(type == "Heart_Rate", date_start %in% xx$date_start) %>% 
  arrange(start_date) %>% View()

# focus on a slice of time
health_df %>% filter(start_date >= ymd_hm("2018-04-13 09:46"), start_date <= ymd_hm("2018-04-13 10:21")) %>% arrange(start_date) %>% View()

ggplot(data = movement, aes(span2)) + 
  geom_bar() +
  facet_wrap(type ~ group, scales = "free", ncol = 3)
```


HKQuantityTypeIdentifierActiveEnergyBurned	1,262,807	0	0	1	1,262,808
HKQuantityTypeIdentifierBasalEnergyBurned

```{r}
basal <- health_df %>% filter(type == "HKQuantityTypeIdentifierBasalEnergyBurned",
                              str_detect(sourceName, "Watch")) %>% 
    arrange(start_date, end_date)
  
basal %>% filter(start_date > lag(end_date)) %>% 
  select(creationDate, start_date, end_date, span, sourceVersion,sourceName, hour)

active <- health_df %>% filter(type == "HKQuantityTypeIdentifierActiveEnergyBurned",
                              str_detect(sourceName, "Watch")) %>% 
    arrange(start_date, end_date)

xx <- active %>% filter(start_date > lag(end_date)) %>% 
  select(creationDate, start_date, end_date, span, sourceVersion,sourceName, hour)

```

There are 761,937 basal energy measurements. For 761,428, the start_date is the same as end_date
for the previous row. That is, the periods covered by the basal energy measurements
cover a continuous period. In only 489 cases the start_date of one
row comes before the end_date of the preceding row.

The active energy readings are not quite as regular. There are 1,246,352 active energy burned
readings in my dataset. Of those, for 88% the start_date is equal to the preceding end_date. There
are 1,000 cases where the start_date is earlier than the preceding end_date.
